{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting text to embeddings...\n",
      "Training XGBoost model...\n",
      "Reclassifying 'Other' samples with nearest category...\n",
      "\n",
      " Final Category Counts (XGBoost + Reclassification):\n",
      "               Category  Count\n",
      "0       General Inquiry    546\n",
      "1            Bug Report    363\n",
      "2       Feature Request    312\n",
      "3  Theoretical Question    493\n",
      "4             Code Help    169\n",
      "\n",
      " Classification completed successfully.\n"
     ]
    }
   ],
   "source": [
    "#Shiqi Zhang, Tyler Stevenson, Zefeng Pei\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from xgboost import XGBClassifier\n",
    "from collections import Counter\n",
    "\n",
    "# Define JSON file paths\n",
    "json_files = [\n",
    "    \"./DevGPT/snapshot_20231012/20231012_232232_hn_sharings.json\",\n",
    "    \"./DevGPT/snapshot_20230803/20230803_105332_hn_sharings.json\"\n",
    "]\n",
    "\n",
    "# Load JSON data\n",
    "def load_conversations(json_files):\n",
    "    conversations_data = []\n",
    "    for file_path in json_files:\n",
    "        try:\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "            for source in data.get(\"Sources\", []):\n",
    "                for chat in source.get(\"ChatgptSharing\", []):\n",
    "                    for conversation in chat.get(\"Conversations\", []):\n",
    "                        conversations_data.append({\n",
    "                            \"Prompt\": conversation.get(\"Prompt\", \"\"),\n",
    "                            \"Answer\": conversation.get(\"Answer\", \"\"),\n",
    "                            \"DateOfConversation\": conversation.get(\"DateOfConversation\", \"\"),\n",
    "                            \"Title\": conversation.get(\"Title\", \"\"),\n",
    "                            \"Source_File\": file_path\n",
    "                        })\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "    return pd.DataFrame(conversations_data)\n",
    "\n",
    "# Load data\n",
    "df_conversations = load_conversations(json_files)\n",
    "\n",
    "# Define categories\n",
    "categories = [\n",
    "    \"Bug Report\", \"Feature Request\", \"Theoretical Question\", \"Code Help\", \"General Inquiry\", \"Other\"\n",
    "]\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'\\W+', ' ', text)  # Remove special characters\n",
    "    return text\n",
    "\n",
    "df_conversations[\"Processed_Prompt\"] = df_conversations[\"Prompt\"].apply(preprocess_text)\n",
    "\n",
    "# Auto-labeling with keyword-based matching\n",
    "def categorize_prompt(prompt):\n",
    "    prompt_lower = prompt.lower()\n",
    "    \n",
    "    if any(word in prompt_lower for word in [\"error\", \"bug\", \"issue\", \"exception\", \"traceback\", \"crash\", \"fail\", \"stuck\", \"debug\"]):\n",
    "        return \"Bug Report\"\n",
    "    elif any(word in prompt_lower for word in [\"feature\", \"add\", \"support\", \"implement\", \"new functionality\", \"request\", \"enhancement\", \"improve\"]):\n",
    "        return \"Feature Request\"\n",
    "    elif any(word in prompt_lower for word in [\"why\", \"how\", \"explain\", \"difference\", \"theory\", \"concept\", \"definition\", \"principle\"]):\n",
    "        return \"Theoretical Question\"\n",
    "    elif any(word in prompt_lower for word in [\"code\", \"function\", \"class\", \"method\", \"best practice\", \"optimize\", \"refactor\", \"debug\", \"syntax\"]):\n",
    "        return \"Code Help\"\n",
    "    elif any(word in prompt_lower for word in [\"what\", \"when\", \"can\", \"possible\", \"is it\", \"should\", \"which\", \"does\"]):\n",
    "        return \"General Inquiry\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "df_conversations[\"Category\"] = df_conversations[\"Prompt\"].apply(categorize_prompt)\n",
    "\n",
    "# Encode categories into numerical labels\n",
    "category_to_label = {category: i for i, category in enumerate(categories)}\n",
    "label_to_category = {i: category for category, i in category_to_label.items()}\n",
    "\n",
    "df_conversations[\"Label\"] = df_conversations[\"Category\"].map(category_to_label)\n",
    "\n",
    "# Train-test split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    df_conversations[\"Processed_Prompt\"].tolist(),\n",
    "    df_conversations[\"Label\"].tolist(),\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Load sentence transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Convert text to embeddings\n",
    "print(\"Converting text to embeddings...\")\n",
    "train_embeddings = model.encode(train_texts, convert_to_numpy=True)\n",
    "test_embeddings = model.encode(test_texts, convert_to_numpy=True)\n",
    "\n",
    "# Train XGBoost classifier\n",
    "print(\"Training XGBoost model...\")\n",
    "xgb_model = XGBClassifier(objective=\"multi:softmax\", num_class=len(categories), eval_metric=\"mlogloss\")\n",
    "xgb_model.fit(train_embeddings, train_labels)\n",
    "\n",
    "# Predict categories\n",
    "predicted_labels = xgb_model.predict(test_embeddings)\n",
    "\n",
    "# Convert predictions back to category names\n",
    "predicted_categories = [label_to_category[label] for label in predicted_labels]\n",
    "\n",
    "# Reclassify \"Other\" samples using nearest category\n",
    "print(\"Reclassifying 'Other' samples with nearest category...\")\n",
    "\n",
    "# Get embeddings for \"Other\" samples\n",
    "df_other = df_conversations[df_conversations[\"Category\"] == \"Other\"]\n",
    "other_texts = df_other[\"Processed_Prompt\"].tolist()\n",
    "other_embeddings = model.encode(other_texts, convert_to_numpy=True)\n",
    "\n",
    "# Compute similarity with known categories\n",
    "category_examples = {\n",
    "    \"Bug Report\": \"I encountered an error in my code.\",\n",
    "    \"Feature Request\": \"I want to add a new functionality.\",\n",
    "    \"Theoretical Question\": \"Can you explain this concept?\",\n",
    "    \"Code Help\": \"How do I fix this function?\",\n",
    "    \"General Inquiry\": \"What is the best way to do this?\"\n",
    "}\n",
    "\n",
    "category_embeddings = model.encode(list(category_examples.values()), convert_to_numpy=True)\n",
    "\n",
    "# Assign the most similar category to \"Other\" samples\n",
    "for i, embedding in enumerate(other_embeddings):\n",
    "    similarities = cosine_similarity([embedding], category_embeddings)[0]\n",
    "    best_category = list(category_examples.keys())[np.argmax(similarities)]\n",
    "    df_conversations.loc[df_other.index[i], \"Category\"] = best_category  # Update category\n",
    "\n",
    "# Count occurrences of each category\n",
    "category_counts = Counter(df_conversations[\"Category\"])\n",
    "\n",
    "# Display results\n",
    "print(\"\\n Final Category Counts (XGBoost + Reclassification):\")\n",
    "print(pd.DataFrame(category_counts.items(), columns=[\"Category\", \"Count\"]))\n",
    "\n",
    "print(\"\\n Classification completed successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
